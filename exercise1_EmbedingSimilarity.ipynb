{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae0dffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4857d1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "✅ Model loaded!\n",
      "Model produces 384 dimensional embeddings\n"
     ]
    }
   ],
   "source": [
    "# Load a small, fast embedding model\n",
    "print(\"Loading embedding model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"✅ Model loaded!\")\n",
    "print(f\"Model produces {model.get_sentence_embedding_dimension()} dimensional embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdeda7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: ['The dog is playing in the park', 'A puppy is running outside', 'The cat is sleeping on the couch', 'Python is a programming language', 'Machine learning models need data', 'I love coding in Python']\n",
      "Embedding shape: (6, 384)\n",
      "Embedding type: <class 'numpy.ndarray'>\n",
      "\n",
      "First 10 values: [[ 0.04757566 -0.07015255  0.06429745 ...  0.07358797  0.01249519\n",
      "   0.01645608]\n",
      " [-0.0252566   0.03054359  0.05249952 ...  0.01063144  0.01476685\n",
      "   0.10832038]\n",
      " [ 0.12203883 -0.04751379 -0.00115909 ...  0.08472569  0.06573964\n",
      "   0.0092331 ]\n",
      " [-0.03537083  0.03816499 -0.04126014 ...  0.11130316  0.19625439\n",
      "  -0.0289743 ]\n",
      " [ 0.0166593  -0.04558858  0.02346507 ...  0.02717924 -0.03379643\n",
      "  -0.05370044]\n",
      " [-0.06430852  0.01564189 -0.0467849  ...  0.15115134  0.10791418\n",
      "  -0.04270949]]\n"
     ]
    }
   ],
   "source": [
    "# Simple example\n",
    "sentences = [\n",
    "    \"The dog is playing in the park\",\n",
    "    \"A puppy is running outside\",\n",
    "    \"The cat is sleeping on the couch\",\n",
    "    \"Python is a programming language\",\n",
    "    \"Machine learning models need data\",\n",
    "    \"I love coding in Python\"\n",
    "]\n",
    "\n",
    "# Generate embedding\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "print(f\"Original text: {sentences}\")\n",
    "print(f\"Embedding shape: {embeddings.shape}\")\n",
    "print(f\"Embedding type: {type(embeddings)}\")\n",
    "print(f\"\\nFirst 10 values: {embeddings[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0a9396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity function ready!\n"
     ]
    }
   ],
   "source": [
    "#3 helper function to calculate similarity scores \n",
    "\n",
    "# def cosine_similarity(a, b):\n",
    "#     return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two vectors.\n",
    "    \n",
    "    Returns a score between -1 and 1 (higher = more similar)\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "print(\"Similarity function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33c49229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper function ready\n"
     ]
    }
   ],
   "source": [
    "def similarity_report(query_index):\n",
    "    query_embedding = embeddings[query_index].reshape(1, -1)\n",
    "    scores = cosine_similarity(query_embedding, embeddings)[0]\n",
    "    \n",
    "    results = list(zip(sentences, scores))\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results\n",
    "\n",
    "print(\"helper function ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd150251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Analysis:\n",
      "\n",
      "Query: \"The dog is playing in the park\"\n",
      "Similarity scores:\n",
      "  -> The dog is playing in the park           : 1.0000\n",
      "  -> A puppy is running outside               : 0.3984\n",
      "  -> The cat is sleeping on the couch         : 0.0714\n",
      "  -> Python is a programming language         : 0.0987\n",
      "  -> Machine learning models need data        : -0.0052\n",
      "  -> I love coding in Python                  : 0.0902\n",
      "\n",
      "Most similar: \"The dog is playing in the park\" (score: 1.0000)\n",
      "Least similar: \"Machine learning models need data\" (score: -0.0052)\n",
      "Observations: The model correctly identifies that 'A puppy is running outside' is most similar because both describe young dogs being active outdoors. 'The cat is sleeping' is least similar due to different animal and action.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate similarity\n",
    "\n",
    "# 4. Calculate similarities\n",
    "\n",
    "print(\"Similarity Analysis:\\n\")\n",
    "\n",
    "# Query 1: \"The dog is playing in the park\" (index 0)\n",
    "query_idx1 = 0\n",
    "similarities1 = [cosine_similarity(embeddings[query_idx1], embeddings[i]) for i in range(len(sentences))]\n",
    "\n",
    "print(f\"Query: \\\"{sentences[query_idx1]}\\\"\")\n",
    "print(\"Similarity scores:\")\n",
    "for i, score in enumerate(similarities1):\n",
    "    print(f\"  -> {sentences[i]:<40} : {score:.4f}\")\n",
    "\n",
    "max_idx1 = np.argmax(similarities1)\n",
    "min_idx1 = np.argmin(similarities1)\n",
    "\n",
    "print(f\"\\nMost similar: \\\"{sentences[max_idx1]}\\\" (score: {similarities1[max_idx1]:.4f})\")\n",
    "print(f\"Least similar: \\\"{sentences[min_idx1]}\\\" (score: {similarities1[min_idx1]:.4f})\")\n",
    "print(\"Observations: The model correctly identifies that 'A puppy is running outside' is most similar \"\n",
    "      \"because both describe young dogs being active outdoors. 'The cat is sleeping' is least similar \"\n",
    "      \"due to different animal and action.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c430ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: \"Python is a programming language\"\n",
      "Similarity scores:\n",
      "  -> The dog is playing in the park           : 0.0987\n",
      "  -> A puppy is running outside               : 0.0395\n",
      "  -> The cat is sleeping on the couch         : 0.0199\n",
      "  -> Python is a programming language         : 1.0000\n",
      "  -> Machine learning models need data        : 0.1133\n",
      "  -> I love coding in Python                  : 0.7304\n",
      "\n",
      "Most similar: \"Python is a programming language\" (score: 1.0000)\n",
      "Least similar: \"The cat is sleeping on the couch\" (score: 0.0199)\n",
      "Observations: The model finds 'I love coding in Python' most similar because both are directly about Python programming. Sentences about dogs and cats score very low, showing strong topic separation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query 2: \"Python is a programming language\" (index 3)\n",
    "query_idx2 = 3\n",
    "similarities2 = [cosine_similarity(embeddings[query_idx2], embeddings[i]) for i in range(len(sentences))]\n",
    "\n",
    "print(f\"Query: \\\"{sentences[query_idx2]}\\\"\")\n",
    "print(\"Similarity scores:\")\n",
    "for i, score in enumerate(similarities2):\n",
    "    print(f\"  -> {sentences[i]:<40} : {score:.4f}\")\n",
    "\n",
    "max_idx2 = np.argmax(similarities2)\n",
    "min_idx2 = np.argmin(similarities2)\n",
    "\n",
    "print(f\"\\nMost similar: \\\"{sentences[max_idx2]}\\\" (score: {similarities2[max_idx2]:.4f})\")\n",
    "print(f\"Least similar: \\\"{sentences[min_idx2]}\\\" (score: {similarities2[min_idx2]:.4f})\")\n",
    "print(\"Observations: The model finds 'I love coding in Python' most similar because both are directly \"\n",
    "      \"about Python programming. Sentences about dogs and cats score very low, showing strong topic separation.\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0dbac514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended similarity threshold: 0.4 - 0.5\n",
      "Reasoning:\n",
      "   • Scores above ~0.5: clearly related (same topic)\n",
      "   • Scores 0.3–0.5: somewhat related (might be useful with more context)\n",
      "   • Scores below ~0.3: unrelated (should be filtered out in RAG retrieval)\n"
     ]
    }
   ],
   "source": [
    "# Recommended threshold\n",
    "print(\"Recommended similarity threshold: 0.4 - 0.5\")\n",
    "print(\"Reasoning:\")\n",
    "print(\"   • Scores above ~0.5: clearly related (same topic)\")\n",
    "print(\"   • Scores 0.3–0.5: somewhat related (might be useful with more context)\")\n",
    "print(\"   • Scores below ~0.3: unrelated (should be filtered out in RAG retrieval)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
